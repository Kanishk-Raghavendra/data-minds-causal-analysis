# Data Minds — Multi-Outcome Causal Analysis of Post-9/11 Airport Security Mandates

This repository contains code, data manifests, and notebooks for a causal inference project using the Global Terrorism Database (GTD). The analysis estimates the effects of post-9/11 airport security mandates across multiple outcomes using Difference-in-Differences (DiD) and a manually implemented Synthetic Control approach.

## Repository structure

Top-level layout:

```
data-minds-causal-analysis/
├── data/
│   ├── raw/         # raw source files (GTD exports, etc.)
│   └── processed/   # cleaned & aggregated datasets used by notebooks
├── notebooks/       # analysis notebooks (see descriptions below)
├── reports/         # generated figures and tables
│   ├── figures/
│   └── tables/
├── requirements.txt
└── README.md
```

## Quick start

1. Clone the repo:

```bash
git clone <repo-url>
cd data-minds-causal-analysis
```

2. Create and activate a Python virtual environment (macOS / Linux):

```bash
python3 -m venv venv
source venv/bin/activate
```

3. Install dependencies:

```bash
pip install -r requirements.txt
```

4. Launch Jupyter Lab or Notebook to run the analysis notebooks:

```bash
jupyter lab
# or
jupyter notebook
```

## Notebooks

- `01_Data_Cleaning_and_Aggregation.ipynb` — load GTD exports, clean event-level data, and aggregate to monthly panel datasets used across outcomes.
- `02_Model_Effectiveness.ipynb` — estimate policy effects using Two-Way Fixed Effects (DiD) specifications and present main results.
- `03_Model_Displacement.ipynb` — investigate displacement or spillover effects across locations/outcomes.
- `04_Model_Sophistication.ipynb` — analyze changes in sophistication or characteristics of events.
- `05_Validation_Event_Study.ipynb` — event-study plots and parallel-trends checks; robustness tests.

## Data

- `data/raw/` should contain original GTD exports and any auxiliary source files. GTD licensing may restrict redistribution — keep raw data out of public forks when required.
- `data/processed/` contains cleaned, documented, and analysis-ready panel files generated by the data cleaning notebook. Do not edit processed files by hand; re-run the cleaning notebook to reproduce them.

If you do not have GTD data, follow the GTD provider instructions to obtain access and place the export files in `data/raw/` before running `01_Data_Cleaning_and_Aggregation.ipynb`.

## Methods (short)

- Difference-in-Differences (Two-Way Fixed Effects) with cluster-robust standard errors for main effect estimation.
- Event-study specification for parallel trends and dynamic effects.
- A manually implemented Synthetic Control approach (weights are computed in notebook code rather than via external SCM packages) to create counterfactuals for treated units.

## Workflow

1. Prepare raw GTD data and place exports in `data/raw/`.
2. Run `01_Data_Cleaning_and_Aggregation.ipynb` to produce `data/processed/` panel files.
3. Run modeling notebooks (`02_...` – `05_...`) to estimate effects, validate assumptions, and generate figures.

## Requirements

See `requirements.txt` for Python dependencies. Common packages used across the notebooks include pandas, numpy, statsmodels, matplotlib, seaborn, and jupyter.

## Contributors

- Lead: Kanishk Raghavendra
- Data & Modeling: Gururaja Rao M, Shashank S Shetty, Kanishk Raghavendra
- Validation & Visuals: Shashank HS

## License

This repository is released under the terms of the included `LICENSE` file.